{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Sat Nov 30 13:36:16 2019\n",
    "\n",
    "@author: Talha Ilyas\n",
    "\"\"\"\n",
    "# Import necessary libraries\n",
    "from keras.datasets import cifar10 # keras in only used for loading the data\n",
    "import numpy\n",
    "import time, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creating the CNN class wiht all essential functions like train, test, conv, back prop etc.\n",
    "'''\n",
    "class CNN:\n",
    "    # initialise the neural network\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        filter_1 : filter size for 1st conv layer [type = tuple] e.g. ->  (5,5)\n",
    "        filter_2 : filter size for 2nd conv layer [type = tuple] e.g. ->  (5,5)\n",
    "        input_nodes : Number of nodes in 1st hidden layer [type = int] e.g. -> 200\n",
    "        h1nodes : Number of nodes in 2nd hidden layer [type = int] e.g. -> 200\n",
    "        h2nodes : Number of nodes in 3rd hidden layer [type = int] e.g. -> 200\n",
    "        opnodes : Number of nodes in ouput layer [type = int] equal to number of classes;\n",
    "                  in case of CIFAR-10 and MNIST -> 10\n",
    "        bias_hid2op : bias vector len. equal to output_nodes\n",
    "        bias_hid1hid2 : bias vector len. equal to nodes_in_2nd_hidden_layer\n",
    "        bias_iphid1 : bias vector len. equal to nodes_in_1st_hidden_layer\n",
    "        momentum : a hyperparameter for gradient descent [type = float] e.g. ->  0.9\n",
    "        BatchSize : for how many times to iterate over whole data [type = int] e.g. ->  50\n",
    "        learningrate : a hyperparameter for gradient descent [type = float] e.g. ->  0.01\n",
    "        decay : a hyperparameter for learning rate decay [type = float] e.g. ->  0.0001\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        '''\n",
    "    def __init__(self, filter_1, filter_2, input_nodes, h1nodes, h2nodes, opnodes,\n",
    "                 bias_hid2op, bias_hid1hid2, bias_iphid1, momentum, BatchSize, learningrate, decay):\n",
    "    # set number of nodes in each input, hidden, output layer\n",
    "        #Two Conv Filters\n",
    "        self.filter1_h, self.filter1_w = filter_1\n",
    "        self.filter2_h, self.filter2_w = filter_2\n",
    "\n",
    "        self.ip_nodes = input_nodes\n",
    "        self.h1_nodes = h1nodes\n",
    "        self.h2_nodes = h2nodes\n",
    "        self.op_nodes = opnodes\n",
    "\n",
    "        self.bias_h2op = bias_hid2op\n",
    "        self.bias_h1h2 = bias_hid1hid2\n",
    "        self.bias_iph1 = bias_iphid1\n",
    "        \n",
    "        self.batch_size = BatchSize\n",
    "        #Momentum\n",
    "        self.beta = momentum\n",
    "        \n",
    "        self.Vdw_h2_op = 0\n",
    "        self.Vdw_h1_h2 = 0\n",
    "        self.Vdw_ip_h1 = 0\n",
    "        \n",
    "        self.Vdb_h2_op = 0\n",
    "        self.Vdb_h1_h2 = 0\n",
    "        self.Vdb_ip_h1 = 0\n",
    "        \n",
    "        self.w_ch8 = numpy.ones((8,1,1,))\n",
    "        #Guassian Normal Distribution pow() means deviation in values is between +- h2_nodes**-0.5 with mean=0\n",
    "        self.w_c11 = numpy.random.normal(0.0, pow(self.filter1_h, -0.5),(3,self.filter1_h, self.filter1_w))\n",
    "        self.w_c12 = numpy.random.normal(0.0, pow(self.filter1_h, -0.5),(3,self.filter1_h, self.filter1_w))\n",
    "        self.w_c13 = numpy.random.normal(0.0, pow(self.filter1_h, -0.5),(3,self.filter1_h, self.filter1_w))\n",
    "        self.w_c14 = numpy.random.normal(0.0, pow(self.filter1_h, -0.5),(3,self.filter1_h, self.filter1_w))\n",
    "        self.w_c15 = numpy.random.normal(0.0, pow(self.filter1_h, -0.5),(3,self.filter1_h, self.filter1_w))\n",
    "        self.w_c16 = numpy.random.normal(0.0, pow(self.filter1_h, -0.5),(3,self.filter1_h, self.filter1_w))\n",
    "        self.w_c17 = numpy.random.normal(0.0, pow(self.filter1_h, -0.5),(3,self.filter1_h, self.filter1_w))\n",
    "        self.w_c18 = numpy.random.normal(0.0, pow(self.filter1_h, -0.5),(3,self.filter1_h, self.filter1_w))\n",
    "        \n",
    "        #2nd Layer\n",
    "        self.w_c21 = numpy.random.normal(0.0, pow(self.filter2_h, -0.5),(8,self.filter2_h, self.filter2_w))\n",
    "        self.w_c22 = numpy.random.normal(0.0, pow(self.filter2_h, -0.5),(8,self.filter2_h, self.filter2_w))\n",
    "        self.w_c23 = numpy.random.normal(0.0, pow(self.filter2_h, -0.5),(8,self.filter2_h, self.filter2_w))\n",
    "        self.w_c24 = numpy.random.normal(0.0, pow(self.filter2_h, -0.5),(8,self.filter2_h, self.filter2_w))\n",
    "        self.w_c25 = numpy.random.normal(0.0, pow(self.filter2_h, -0.5),(8,self.filter2_h, self.filter2_w))\n",
    "        self.w_c26 = numpy.random.normal(0.0, pow(self.filter2_h, -0.5),(8,self.filter2_h, self.filter2_w))\n",
    "        self.w_c27 = numpy.random.normal(0.0, pow(self.filter2_h, -0.5),(8,self.filter2_h, self.filter2_w))\n",
    "        self.w_c28 = numpy.random.normal(0.0, pow(self.filter2_h, -0.5),(8,self.filter2_h, self.filter2_w))\n",
    "        \n",
    "        # Linking weights\n",
    "        #Guassian Normal Distribution pow() means deviation in values is between +- h2_nodes**-0.5 with mean=0\n",
    "        self.w_ip_h1 = numpy.random.normal(0.0, pow(self.h1_nodes, -0.5),(self.h1_nodes, self.ip_nodes))\n",
    "        self.w_h1_h2 = numpy.random.normal(0.0, pow(self.h2_nodes, -0.5),(self.h2_nodes, self.h1_nodes))\n",
    "        self.w_h2_op = numpy.random.normal(0.0, pow(self.op_nodes, -0.5),(self.op_nodes, self.h2_nodes))\n",
    "        #Linking Biases\n",
    "        #Guassian Normal Distribution pow() means deviation in values is between +- h2_nodes**-0.5 with mean=0\n",
    "        self.bias_h2_op = numpy.random.normal(0.0, pow(self.bias_h2op, -0.5),(self.bias_h2op, 1))\n",
    "        self.bias_h1_h2 = numpy.random.normal(0.0, pow(self.bias_h1h2, -0.5),(self.bias_h1h2, 1))\n",
    "        self.bias_ip_h1 = numpy.random.normal(0.0, pow(self.bias_iph1, -0.5),(self.bias_iph1, 1))\n",
    "        \n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        self.lr_decay = decay\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.Activate = lambda x: scipy.special.expit(x)\n",
    "        pass\n",
    "    #--------------------------Derivative of Activation Functions----------------------------\n",
    "    \n",
    "    def de_Activate(self,x):\n",
    "        self.x = x * (1 - x)\n",
    "        return self.x\n",
    "    '''\n",
    "    def Activate(self,x):\n",
    "        self.x = numpy.where(x<=0, 0, x)\n",
    "        return self.x\n",
    "    def de_Activate(self,x):\n",
    "        self.x = numpy.where(x<=0, 0, 1)\n",
    "        return self.x\n",
    "    '''\n",
    "    #---------------Multi Layer/channel  Conv 1st filter----------------------------------------------------\n",
    "    def mc_conv(self, image, flter):\n",
    "        X = flter\n",
    "        Y = image\n",
    "        ch_f,k,l=X.shape\n",
    "        ch_i,i,j=Y.shape\n",
    "        Op = numpy.zeros((i-k+1,i-k+1))\n",
    "        for b in range(j-l+1):\n",
    "          for a in range(i-k+1):\n",
    "              Op[b,a] = numpy.sum(numpy.multiply(X[:,:,:],Y[:,b:k+b,a:a+k]))    \n",
    "        return Op\n",
    "    #----------------multi filter output-----------------------  \n",
    "    '''Op_f = numpy.stack((Op,Op), axis=0)'''\n",
    "    #---------------multi filter pooling---------------------------------\n",
    "    def mf_pooling(self, Op_f):\n",
    "        ip = Op_f\n",
    "        cd,c,d = ip.shape\n",
    "        e = c-c//2\n",
    "        pool = numpy.zeros((cd,e,e))\n",
    "        locations = numpy.zeros((cd,e,e))\n",
    "        for cd in range(cd):\n",
    "            for g in range(c-e):\n",
    "                for f in range(c-e):\n",
    "                    pool[cd,g,f] = numpy.max(ip[cd,g*2:g+g+2,f*2:f+f+2])\n",
    "                    locations[cd,g,f] = numpy.argmax(ip[cd,g*2:g+g+2,f*2:f+f+2])\n",
    "        return locations,pool\n",
    "    #------------------------Back Pool Multi Layer/Channel---------------------------\n",
    "    def b_mf_pooling(self, before_pooling_shape,locations,pool_values):\n",
    "        cache1 = pool_values\n",
    "        cache2 = before_pooling_shape.shape\n",
    "        cache3 = locations.astype(int)\n",
    "        b_Op = numpy.zeros(cache2)\n",
    "        cd,t,u = cache1.shape\n",
    "        for cd in range(cd):\n",
    "            for j in range(u):\n",
    "                for i in range(t):\n",
    "                   a = cache3[cd,j,i]\n",
    "                   numpy.put(b_Op[cd,j*2:j+j+2,i*2:i+i+2],a, cache1[cd,j,i])\n",
    "        return b_Op\n",
    "    #---------------------Error Splitting----------------------------------------------\n",
    "    '''x,y,z = numpy.split(X1,3)'''\n",
    "    #-----------------------Back Conv Multi channel--------------------------------\n",
    "    def b_mc_conv(self, b_pool_op, image):  \n",
    "            X = b_pool_op\n",
    "            Y = image\n",
    "            ch_f,k,l=X.shape\n",
    "            ch_i,i,j=Y.shape\n",
    "            f_g = numpy.zeros((i-k+1,i-k+1))\n",
    "            for b in range(j-l+1):\n",
    "                for a in range(i-k+1):\n",
    "                    f_g[b,a] = numpy.sum(numpy.multiply(X[:,:,:],Y[:,b:k+b,a:a+k]))\n",
    "            return f_g\n",
    "    #--------------------Channel wise conv----------------------------------------------------\n",
    "    def ch_conv(self, f_g, pool):\n",
    "            d,e,f = f_g.shape \n",
    "            a,b,c = pool.shape\n",
    "            f_grad = numpy.empty((0,b-e+1,c-f+1))\n",
    "            for i in range(a):\n",
    "                temp = pool[i,:,:]  #taking 1 channel at a time\n",
    "                temp = numpy.array(temp, ndmin=3)\n",
    "                f_gad = self.b_mc_conv(f_g, temp)\n",
    "                f_gad = numpy.array(f_gad, ndmin=3)\n",
    "                f_grad = numpy.append(f_grad,f_gad,axis=0)\n",
    "            return f_grad\n",
    "    #------------------------------------------------------------ Train the CNN------------------------------------\n",
    "    def train(self, inputs_list, targets_list,iteration,epoch):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = inputs_list\n",
    "        targets = targets_list\n",
    "        t = iteration\n",
    "        #e = epoch\n",
    "        #--------------Learning Rate Decay--------------------\n",
    "        lr = self.lr\n",
    "        lr *=  (1. / (1. + (self.lr_decay * t)))\n",
    "        #------Conv 1 ------\n",
    "        conv11_op = self.mc_conv(inputs,self.w_c11)\n",
    "        conv12_op = self.mc_conv(inputs,self.w_c12)\n",
    "        conv13_op = self.mc_conv(inputs,self.w_c13)\n",
    "        conv14_op = self.mc_conv(inputs,self.w_c14)\n",
    "        conv15_op = self.mc_conv(inputs,self.w_c15)\n",
    "        conv16_op = self.mc_conv(inputs,self.w_c16)\n",
    "        conv17_op = self.mc_conv(inputs,self.w_c17)\n",
    "        conv18_op = self.mc_conv(inputs,self.w_c18)\n",
    "        \n",
    "        #-----------Making Op 1 by Stacking----------\n",
    "        conv1_op = numpy.stack((conv11_op,conv12_op,conv13_op,conv14_op,conv15_op,conv16_op,conv17_op,conv18_op), axis=0)\n",
    "        #------activate----\n",
    "        conv1_opA = self.Activate(conv1_op)\n",
    "        #------Pool 1------\n",
    "        locations1,pool1_op = self.mf_pooling(conv1_opA)\n",
    "        \n",
    "        #---------Conv 2-----\n",
    "        conv21_op = self.mc_conv(pool1_op,self.w_c21)\n",
    "        conv22_op = self.mc_conv(pool1_op,self.w_c22)\n",
    "        conv23_op = self.mc_conv(pool1_op,self.w_c23)\n",
    "        conv24_op = self.mc_conv(pool1_op,self.w_c24)\n",
    "        conv25_op = self.mc_conv(pool1_op,self.w_c25)\n",
    "        conv26_op = self.mc_conv(pool1_op,self.w_c26)\n",
    "        conv27_op = self.mc_conv(pool1_op,self.w_c27)\n",
    "        conv28_op = self.mc_conv(pool1_op,self.w_c28)\n",
    "        \n",
    "        #-----------Making Op 1 by Stacking----------\n",
    "        conv2_op = numpy.stack((conv21_op,conv22_op,conv23_op,conv24_op,conv25_op,conv26_op,conv27_op,conv28_op), axis=0)\n",
    "        #-----Activate------\n",
    "        conv2_opA = self.Activate(conv2_op)\n",
    "        #-----Pool 2------\n",
    "        locations2,pool2_op = self.mf_pooling(conv2_opA)\n",
    "        \n",
    "        #-----Flattening----------\n",
    "        t = pool2_op.flatten()\n",
    "        temp = pool2_op.shape\n",
    "        CNN_op = t.reshape(self.ip_nodes,1)\n",
    "        \n",
    "        X_h1 = numpy.add(numpy.dot(self.w_ip_h1, CNN_op) , self.bias_ip_h1)\n",
    "        O_h1 = self.Activate(X_h1)\n",
    "        # calculate signals into hidden layer\n",
    "        X_h2 = numpy.add(numpy.dot(self.w_h1_h2, O_h1) , self.bias_h1_h2)\n",
    "        O_h2 = self.Activate(X_h2)\n",
    "        # calculate signals into final output layer\n",
    "        X_op = numpy.add(numpy.dot(self.w_h2_op, O_h2) , self.bias_h2_op)\n",
    "        O_op = self.Activate(X_op)\n",
    "        # output layer error is the (target - actual)\n",
    "        errors_op = targets - O_op\n",
    "        errors_h2 = numpy.dot(self.w_h2_op.T, errors_op)\n",
    "        errors_h1 = numpy.dot(self.w_h1_h2.T, errors_h2)\n",
    "        errors_ip = numpy.dot(self.w_ip_h1.T, errors_h1)\n",
    "        errors_ipR = errors_ip.reshape(temp)\n",
    "        \n",
    "        \n",
    "        errors_ipRB = self.b_mf_pooling(conv2_op, locations2, errors_ipR)\n",
    "        errors_c2 = errors_ipRB #8 channel error\n",
    "        \n",
    "        \n",
    "        errors_c2P = numpy.pad(errors_c2,((0,0),(4,4),(4,4)),'constant', constant_values=(0))\n",
    "        \n",
    "        w_c21F = numpy.rot90(self.w_c21,k=2)\n",
    "        w_c22F = numpy.rot90(self.w_c22,k=2)\n",
    "        w_c23F = numpy.rot90(self.w_c23,k=2)\n",
    "        w_c24F = numpy.rot90(self.w_c24,k=2)\n",
    "        w_c25F = numpy.rot90(self.w_c25,k=2)\n",
    "        w_c26F = numpy.rot90(self.w_c26,k=2)\n",
    "        w_c27F = numpy.rot90(self.w_c27,k=2)\n",
    "        w_c28F = numpy.rot90(self.w_c28,k=2)\n",
    "        \n",
    "        \n",
    "        errors_c11 = self.mc_conv(errors_c2P, w_c21F)\n",
    "        errors_c12 = self.mc_conv(errors_c2P, w_c22F)\n",
    "        errors_c13 = self.mc_conv(errors_c2P, w_c23F)\n",
    "        errors_c14 = self.mc_conv(errors_c2P, w_c24F)\n",
    "        errors_c15 = self.mc_conv(errors_c2P, w_c25F)\n",
    "        errors_c16 = self.mc_conv(errors_c2P, w_c26F)\n",
    "        errors_c17 = self.mc_conv(errors_c2P, w_c27F)\n",
    "        errors_c18 = self.mc_conv(errors_c2P, w_c28F)\n",
    "        \n",
    "        errors_c1 =  numpy.stack((errors_c11,errors_c12,errors_c13,errors_c14,errors_c15,errors_c16,errors_c17,errors_c18), axis=0)\n",
    "        \n",
    "        errors_c1B = self.b_mf_pooling(conv1_op, locations1, errors_c1)#8 channel\n",
    "        \n",
    "        #----------------Splitting Errors to 2D for 3D------------------------\n",
    "        \n",
    "        self.dw_h2_op = numpy.dot((errors_op * self.de_Activate(O_op)), numpy.transpose(O_h2))\n",
    "        self.dw_h1_h2 = numpy.dot((errors_h2 * self.de_Activate(O_h2)), numpy.transpose(O_h1))\n",
    "        self.dw_ip_h1 = numpy.dot((errors_h1 * self.de_Activate(O_h1)), numpy.transpose(CNN_op))\n",
    "        #For Biases\n",
    "        self.db_h2_op = (numpy.sum(errors_op *self.de_Activate(O_op))) / self.batch_size\n",
    "        self.db_h1_h2 = (numpy.sum(errors_h2 *self.de_Activate(O_h2))) / self.batch_size\n",
    "        self.db_ip_h1 = (numpy.sum(errors_h1 *self.de_Activate(O_h1))) / self.batch_size\n",
    "        \n",
    "        self.Vdw_h2_op =  beta*self.Vdw_h2_op +(1-beta)*self.dw_h2_op\n",
    "        self.Vdw_h1_h2 =  beta*self.Vdw_h1_h2 +(1-beta)*self.dw_h1_h2\n",
    "        self.Vdw_ip_h1 =  beta*self.Vdw_ip_h1 +(1-beta)*self.dw_ip_h1\n",
    "        \n",
    "        self.Vdb_h2_op =  beta*self.Vdb_h2_op +(1-beta)*self.db_h2_op\n",
    "        self.Vdb_h1_h2 =  beta*self.Vdb_h1_h2 +(1-beta)*self.db_h1_h2\n",
    "        self.Vdb_ip_h1 =  beta*self.Vdb_ip_h1 +(1-beta)*self.db_ip_h1\n",
    "        #------Back Conv-------------------------------------------------------------------------\n",
    "        f_g2 = errors_c2 * self.de_Activate(conv2_opA)\n",
    "        f_g21,f_g22,f_g23,f_g24,f_g25,f_g26,f_g27,f_g28 = numpy.split(f_g2,8)\n",
    "        \n",
    "        f_grad21 = self.ch_conv(f_g21,pool1_op)\n",
    "        self.w_c21 += lr * f_grad21 \n",
    "        \n",
    "        f_grad22 = self.ch_conv(f_g22,pool1_op)\n",
    "        self.w_c22 += lr * f_grad22\n",
    "        \n",
    "        f_grad23 = self.ch_conv(f_g23,pool1_op)\n",
    "        self.w_c23 += lr * f_grad23\n",
    "        \n",
    "        f_grad24 = self.ch_conv(f_g24,pool1_op)\n",
    "        self.w_c24 += lr * f_grad24\n",
    "        \n",
    "        f_grad25 = self.ch_conv(f_g25,pool1_op)\n",
    "        self.w_c25 += lr * f_grad25\n",
    "        \n",
    "        f_grad26 = self.ch_conv(f_g26,pool1_op)\n",
    "        self.w_c26 += lr * f_grad26\n",
    "        \n",
    "        f_grad27 = self.ch_conv(f_g27,pool1_op)\n",
    "        self.w_c27 += lr * f_grad27\n",
    "        \n",
    "        f_grad28 = self.ch_conv(f_g28,pool1_op)\n",
    "        self.w_c28 += lr * f_grad28\n",
    "        \n",
    "        #---------------------------------------------------------- \n",
    "        f_g1 = errors_c1B * self.de_Activate(conv1_opA)\n",
    "        f_g11,f_g12,f_g13,f_g14,f_g15,f_g16,f_g17,f_g18 = numpy.split(f_g1,8)\n",
    "        \n",
    "        f_grad11 = self.ch_conv(f_g11,inputs)\n",
    "        self.w_c11 += lr * f_grad11 \n",
    "        \n",
    "        f_grad12 = self.ch_conv(f_g12,inputs)\n",
    "        self.w_c12 += lr * f_grad12 \n",
    "        \n",
    "        f_grad13 = self.ch_conv(f_g13,inputs)\n",
    "        self.w_c13 += lr * f_grad13\n",
    "        \n",
    "        f_grad14 = self.ch_conv(f_g14,inputs)\n",
    "        self.w_c14 += lr * f_grad14 \n",
    "        \n",
    "        f_grad15 = self.ch_conv(f_g15,inputs)\n",
    "        self.w_c15 += lr * f_grad15\n",
    "        \n",
    "        f_grad16 = self.ch_conv(f_g16,inputs)\n",
    "        self.w_c16 += lr * f_grad16 \n",
    "        \n",
    "        f_grad17 = self.ch_conv(f_g17,inputs)\n",
    "        self.w_c17 += lr * f_grad17 \n",
    "        \n",
    "        f_grad18 = self.ch_conv(f_g18,inputs)\n",
    "        self.w_c18 += lr * f_grad18 \n",
    "        \n",
    "        \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.w_h2_op += lr * self.Vdw_h2_op\n",
    "        self.w_h1_h2 += lr * self.Vdw_h1_h2\n",
    "        self.w_ip_h1 += lr * self.Vdw_ip_h1\n",
    "        \n",
    "        # update the biases for the links between the hidden and output layers\n",
    "        self.bias_h2_op += lr * self.Vdb_h2_op\n",
    "        self.bias_h1_h2 += lr * self.Vdb_h1_h2\n",
    "        self.bias_ip_h1 += lr * self.Vdb_ip_h1\n",
    "        \n",
    "        return errors_op,lr,conv23_op,conv21_op\n",
    "# query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = inputs_list\n",
    "        #------Conv 1 ------\n",
    "        conv11_op = self.mc_conv(inputs,self.w_c11)\n",
    "        conv12_op = self.mc_conv(inputs,self.w_c12)\n",
    "        conv13_op = self.mc_conv(inputs,self.w_c13)\n",
    "        conv14_op = self.mc_conv(inputs,self.w_c14)\n",
    "        conv15_op = self.mc_conv(inputs,self.w_c15)\n",
    "        conv16_op = self.mc_conv(inputs,self.w_c16)\n",
    "        conv17_op = self.mc_conv(inputs,self.w_c17)\n",
    "        conv18_op = self.mc_conv(inputs,self.w_c18)\n",
    "        \n",
    "        #-----------Making Op 1 by Stacking----------\n",
    "        conv1_op = numpy.stack((conv11_op,conv12_op,conv13_op,conv14_op,conv15_op,conv16_op,conv17_op,conv18_op), axis=0)\n",
    "        #------activate----\n",
    "        conv1_opA = self.Activate(conv1_op)\n",
    "        #------Pool 1------\n",
    "        locations1,pool1_op = self.mf_pooling(conv1_opA)\n",
    "        \n",
    "        #---------Conv 2-----\n",
    "        conv21_op = self.mc_conv(pool1_op,self.w_c21)\n",
    "        conv22_op = self.mc_conv(pool1_op,self.w_c22)\n",
    "        conv23_op = self.mc_conv(pool1_op,self.w_c23)\n",
    "        conv24_op = self.mc_conv(pool1_op,self.w_c24)\n",
    "        conv25_op = self.mc_conv(pool1_op,self.w_c25)\n",
    "        conv26_op = self.mc_conv(pool1_op,self.w_c26)\n",
    "        conv27_op = self.mc_conv(pool1_op,self.w_c27)\n",
    "        conv28_op = self.mc_conv(pool1_op,self.w_c28)\n",
    "        \n",
    "        \n",
    "        #-----------Making Op 1 by Stacking----------\n",
    "        conv2_op = numpy.stack((conv21_op,conv22_op,conv23_op,conv24_op,conv25_op,conv26_op,conv27_op,conv28_op), axis=0)\n",
    "        #-----Activate------\n",
    "        conv2_opA = self.Activate(conv2_op)\n",
    "        #-----Pool 2------\n",
    "        locations2,pool2_op = self.mf_pooling(conv2_opA)\n",
    "        #-----Flattening----------\n",
    "        t = pool2_op.flatten()\n",
    "        CNN_op = t.reshape(self.ip_nodes,1)\n",
    "\n",
    "        # calculate signals into 1st hidden layer\n",
    "        X_h1 = numpy.add(numpy.dot(self.w_ip_h1, CNN_op) , self.bias_ip_h1)\n",
    "        O_h1 = self.Activate(X_h1)\n",
    "        # calculate signals into 2nd hidden layer\n",
    "        X_h2 = numpy.add(numpy.dot(self.w_h1_h2, O_h1) , self.bias_h1_h2)\n",
    "        O_h2 = self.Activate(X_h2)\n",
    "        # calculate signals into final output layer\n",
    "        X_op = numpy.add(numpy.dot(self.w_h2_op, O_h2) , self.bias_h2_op)\n",
    "        O_op = self.Activate(X_op)\n",
    "        return O_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================== \n",
      "For full data set it'll take around 4 hours one epoch maybe more!\n",
      " ======================================================================\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Define hyperparameters and load the data\n",
    "'''\n",
    "print(70*'=', \"\\nFor full data set it'll take around 1 hour one epoch maybe more!\\n\", 70*'=')\n",
    "# No. of training and testing instances you want ot run your algorithm\n",
    "X = 50000   #Training Instances\n",
    "Y = 10000   #Testing Instances\n",
    "# number of input, hidden and output nodes\n",
    "filter_1 = (5,5)\n",
    "filter_2 = (5,5)\n",
    "input_nodes = 200\n",
    "nodes_in_1st_hidden_layer = 40\n",
    "nodes_in_2nd_hidden_layer = 40\n",
    "output_nodes = 10\n",
    "# learning rate\n",
    "learning_rate = 0.01\n",
    "decay = 0.0001\n",
    "#ADAM 1st and 2nd Moments\n",
    "beta = 0.9\n",
    "#For scaling Bias Updates\n",
    "Global_Batchsize = 1 #Fixed for this Algorithm\n",
    "#Epochs -or- iteration\n",
    "epochs = 5\n",
    "#Data Aranging for NN Class\n",
    "hidden1_nodes = nodes_in_1st_hidden_layer\n",
    "hidden2_nodes = nodes_in_2nd_hidden_layer\n",
    "bias_iph1 = nodes_in_1st_hidden_layer\n",
    "bias_h1h2 = nodes_in_2nd_hidden_layer\n",
    "bias_h2op = output_nodes\n",
    "# create instance of neural network\n",
    "n = CNN(filter_1, filter_2, input_nodes, hidden1_nodes,hidden2_nodes, output_nodes, bias_h2op, bias_h1h2, bias_iph1, beta, Global_Batchsize, learning_rate, decay)\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------Loading Training Data---------------------------------------\n",
    "y_train =  numpy.reshape(y_train,(50000))\n",
    "inputs_train = ((x_train / 255.0) * 0.99) + 0.01\n",
    "inputs_train = numpy.reshape(inputs_train,(50000,1024,3))\n",
    "targets_train = numpy.zeros([10,50000]) + 0.01\n",
    "for c in range(len(y_train)):\n",
    "   r = y_train[c]\n",
    "   targets_train[r][c] = 0.99 \n",
    "pass\n",
    "inputs_small = inputs_train[0:X,:,:]\n",
    "inputs_small = numpy.reshape(inputs_small,(X,1024,3))\n",
    "inputs_small = inputs_small.T\n",
    "\n",
    "targets_small = targets_train[:,0:X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------Testing data-------------------------------------------------\n",
    "inputs_test = ((x_test / 255.0) * 0.99) + 0.01\n",
    "inputs_test = numpy.reshape(inputs_test,(10000,1024,3))\n",
    "inputs_smalltest = inputs_test[0:Y,:,:]\n",
    "inputs_smalltest = numpy.reshape(inputs_smalltest,(Y,1024,3))\n",
    "inputs_smalltest = inputs_smalltest.T\n",
    "\n",
    "test_data_label = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training   Epoch 1: 100%|██████████████████████████████████████████████████████| 50000/50000 [1:11:17<00:00, 11.69it/s]\n",
      "Validating Epoch 1: 100%|████████████████████████████████████████████████████████| 10000/10000 [09:04<00:00, 18.38it/s]\n",
      "\n",
      "After 1  Epoch Accuracy= 10.0 %\n",
      "\n",
      "Training   Epoch 2: 100%|██████████████████████████████████████████████████████| 50000/50000 [1:11:40<00:00, 11.63it/s]\n",
      "Validating Epoch 2: 100%|████████████████████████████████████████████████████████| 10000/10000 [09:09<00:00, 18.20it/s]\n",
      "\n",
      "After 2  Epoch Accuracy= 20.84 %\n",
      "\n",
      "Training   Epoch 3: 100%|██████████████████████████████████████████████████████| 50000/50000 [1:11:45<00:00, 11.61it/s]\n",
      "Validating Epoch 3: 100%|████████████████████████████████████████████████████████| 10000/10000 [09:20<00:00, 17.83it/s]\n",
      "\n",
      "After 3  Epoch Accuracy= 22.34 %\n",
      "\n",
      "Training   Epoch 4:  50%|████████████████████████████▎                           | 25238/50000 [36:08<35:39, 11.57it/s]"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------Training NN----------------------------------------------------\n",
    "cost,accuracy = [],[]\n",
    "plot_epoch = epochs\n",
    "go1 = time.time()\n",
    "for e in range(epochs):\n",
    "    inputs_train_batch, targets_train_bacth = [] , []\n",
    "    Batch_size = Global_Batchsize\n",
    "    BS_loop = Batch_size\n",
    "    Batches1 = X / Batch_size \n",
    "    Batches1 = int(Batches1)\n",
    "    \n",
    "    start = 0\n",
    "    go2 = time.time()\n",
    "    for i in trange(Batches1, desc= 'Training   Epoch {}'.format(e+1)):\n",
    "        inputs_train_batch = inputs_small[:,:,start:Batch_size]\n",
    "        inputs_train_batch = numpy.reshape(inputs_train_batch,(3,32,32))\n",
    "        targets_train_bacth = targets_small[:, start:Batch_size]\n",
    "        Errors_train,final_lr,c1_grad,c2_grad = n.train(inputs_train_batch, targets_train_bacth,i,e)\n",
    "        start = Batch_size\n",
    "        Batch_size = Batch_size + BS_loop\n",
    "        #Cost Calculate\n",
    "        Average_error = numpy.sum(Errors_train,axis=0) / 10\n",
    "        Cost_func =  (1/ (2 * BS_loop)) * (sum(Average_error)**2)\n",
    "        pass\n",
    "    cost.append(Cost_func)\n",
    "    inputs_test_batch, targets_test_bacth = [] , []\n",
    "    Op3 =numpy.empty((10,0))\n",
    "    Batch_size = Global_Batchsize\n",
    "    BS_loop = Batch_size\n",
    "    Batches2 = Y / Batch_size \n",
    "    Batches2 = int(Batches2)\n",
    "    start1 = 0\n",
    "#------------------------------------------Performance Measure--------------------------------------------\n",
    "    for j in trange(Batches2, desc=\"Validating Epoch {}\".format(e+1)):\n",
    "        inputs_test_batch = inputs_smalltest[:,:,start1:Batch_size]\n",
    "        inputs_test_batch = numpy.reshape(inputs_test_batch,(3,32,32))\n",
    "        outputs = n.query(inputs_test_batch)\n",
    "        start1 = Batch_size\n",
    "        Batch_size = Batch_size + BS_loop\n",
    "        Op3=numpy.append(Op3,outputs,axis=1)\n",
    "        pass\n",
    "    correct=0\n",
    "    label = numpy.argmax(Op3,axis=0)\n",
    "    for z in range(Y):\n",
    "        if (test_data_label[z]==label[z]):\n",
    "           correct+=1\n",
    "    Performance = correct / Y\n",
    "    print(\"\\nAfter\", e+1,\" Epoch Accuracy=\", Performance * 100,'%\\n', file=sys.stderr)\n",
    "    accuracy.append(Performance)\n",
    "    end2 = time.time() - go2\n",
    "pass\n",
    "end1 = time.time() - go1\n",
    "max_performance = numpy.max(accuracy)\n",
    "EPOCH = numpy.argmax(accuracy) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \n",
      " %  Final Result on CIFAR_10 %\n",
      " %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "\n",
      "The Optimization Algorithm was Stochastic G.D on CNN with Momentum ans L.R Decay\n",
      "\n",
      "Time taken for 1 Epoch        = 0.07757573127746582 Minutes\n",
      "Total time taken for training = 0.0065841305255889895 Hours\n",
      "Filter Size                   = (5, 5) \n",
      "No. of hidden Nodes= 40\n",
      "Training Set Size  = 50 Test Set Size= 10 Number of Epochs= 5\n",
      "Initial L.R         = 0.01 Final L.R= 0.009951238929246693 LR Decay 0.0001 Momentum= 0.9\n",
      "Max Performance     = 0.0 %  at Epoch # 1\n"
     ]
    }
   ],
   "source": [
    "#------------------------------Optimizayion Algorithm & Printing------------------------\n",
    "print(30*'%',\"\\n %  Final Result on CIFAR_10 %\\n\",30*'%',)\n",
    "print(\"\\nThe Optimization Algorithm was Stochastic G.D on CNN with Momentum ans L.R Decay\\n\")\n",
    "print(\"Time taken for 1 Epoch        =\",end2/60,'Minutes')\n",
    "print(\"Total time taken for training =\",end1/3600,'Hours')\n",
    "print('Filter Size                   =',filter_1,\"\\nNo. of hidden Nodes=\",nodes_in_1st_hidden_layer)\n",
    "print (\"Training Set Size  =\", X, \"Test Set Size=\", Y, \"Number of Epochs=\", epochs)\n",
    "print(\"Initial L.R         =\", learning_rate,\"Final L.R=\", final_lr,\"LR Decay\",decay, \"Momentum=\", beta)\n",
    "print(\"Max Performance     =\", max_performance * 100,'%  at Epoch #',EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-----------------------------------Plotting---------------------------------------------\n",
    "\n",
    "plot = plot_epoch\n",
    "#Learning Curve\n",
    "p = numpy.linspace(1,plot_epoch,plot_epoch)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.plot(p, cost, 'b')\n",
    "plt.xlabel('No. of Epochs')\n",
    "plt.ylabel('Cost Function')\n",
    "plt.show()\n",
    "#Performance Curve\n",
    "p = numpy.linspace(1,plot_epoch,plot_epoch)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.plot(p, accuracy, 'g')\n",
    "plt.xlabel('No. of Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "#plt.imshow(c1_grad,  interpolation=\"nearest\")\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
